{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPOydZDitr7YCpYVcKg0KYm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Caiopsc/lia1_2025_1/blob/main/Entregas%20-%20Caio%20Pantale%C3%A3o_atividade_capitulo_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "inyYcbNO8kCr",
        "outputId": "3c2a6f72-9868-4997-bf83-c419b8b01886"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "\n",
            "=== Testando SVR ===\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-1-83f26a67fc51>:56: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  housing[\"income_cat\"].where(housing[\"income_cat\"] < 5, 5.0, inplace=True)\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"Tarefa semana santa.ipynb\n",
        "\n",
        "Automatically generated by Colab.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/1uwddm91zdks8C_OpRx1DyQ9536T34kki\n",
        "\"\"\"\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "import tarfile\n",
        "from six.moves import urllib\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.pipeline import Pipeline, FeatureUnion\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_score, StratifiedShuffleSplit\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from scipy.stats import randint, uniform\n",
        "\n",
        "# Configuração inicial\n",
        "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml/master/\"\n",
        "HOUSING_PATH = os.path.join(\"datasets\", \"housing\")\n",
        "HOUSING_URL = DOWNLOAD_ROOT + \"datasets/housing/housing.tgz\"\n",
        "\n",
        "# Função para baixar os dados\n",
        "def fetch_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH):\n",
        "    if not os.path.isdir(housing_path):\n",
        "        os.makedirs(housing_path)\n",
        "    tgz_path = os.path.join(housing_path, \"housing.tgz\")\n",
        "    urllib.request.urlretrieve(housing_url, tgz_path)\n",
        "    housing_tgz = tarfile.open(tgz_path)\n",
        "    housing_tgz.extractall(path=housing_path)\n",
        "    housing_tgz.close()\n",
        "\n",
        "# Função para carregar os dados\n",
        "def load_housing_data(housing_path=HOUSING_PATH):\n",
        "    csv_path = os.path.join(housing_path, \"housing.csv\")\n",
        "    return pd.read_csv(csv_path)\n",
        "\n",
        "# Baixando e carregando os dados\n",
        "fetch_housing_data()\n",
        "housing = load_housing_data()\n",
        "\n",
        "# Pré-processamento inicial\n",
        "housing[\"income_cat\"] = np.ceil(housing[\"median_income\"] / 1.5)\n",
        "housing[\"income_cat\"].where(housing[\"income_cat\"] < 5, 5.0, inplace=True)\n",
        "\n",
        "# Divisão estratificada\n",
        "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
        "for train_index, test_index in split.split(housing, housing[\"income_cat\"]):\n",
        "    strat_train_set = housing.loc[train_index]\n",
        "    strat_test_set = housing.loc[test_index]\n",
        "\n",
        "# Removendo a categoria de renda\n",
        "for set_ in (strat_train_set, strat_test_set):\n",
        "    set_.drop(\"income_cat\", axis=1, inplace=True)\n",
        "\n",
        "# Preparando os dados\n",
        "housing = strat_train_set.drop(\"median_house_value\", axis=1)\n",
        "housing_labels = strat_train_set[\"median_house_value\"].copy()\n",
        "\n",
        "# Classes personalizadas\n",
        "class CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, add_bedrooms_per_room=True):\n",
        "        self.add_bedrooms_per_room = add_bedrooms_per_room\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X, y=None):\n",
        "        rooms_per_household = X[:, 3] / X[:, 6]\n",
        "        population_per_household = X[:, 5] / X[:, 6]\n",
        "        if self.add_bedrooms_per_room:\n",
        "            bedrooms_per_room = X[:, 4] / X[:, 3]\n",
        "            return np.c_[X, rooms_per_household, population_per_household, bedrooms_per_room]\n",
        "        else:\n",
        "            return np.c_[X, rooms_per_household, population_per_household]\n",
        "\n",
        "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, attribute_names):\n",
        "        self.attribute_names = attribute_names\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        return X[self.attribute_names].values\n",
        "\n",
        "class FeatureSelector(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, feature_importances, threshold=0.01):\n",
        "        self.feature_importances = feature_importances\n",
        "        self.threshold = threshold\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        important_features = self.feature_importances >= self.threshold\n",
        "        return X[:, important_features]\n",
        "\n",
        "# Definindo atributos\n",
        "num_attribs = list(housing.select_dtypes(include=[np.number]).columns)\n",
        "cat_attribs = [\"ocean_proximity\"]\n",
        "\n",
        "# Pipeline numérico\n",
        "num_pipeline = Pipeline([\n",
        "    ('selector', DataFrameSelector(num_attribs)),\n",
        "    ('imputer', SimpleImputer(strategy=\"median\")),\n",
        "    ('attribs_adder', CombinedAttributesAdder()),\n",
        "    ('std_scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "# Pipeline categórico\n",
        "cat_pipeline = Pipeline([\n",
        "    ('selector', DataFrameSelector(cat_attribs)),\n",
        "    ('one_hot_encoder', OneHotEncoder())\n",
        "])\n",
        "\n",
        "# Pipeline completo\n",
        "full_pipeline = FeatureUnion(transformer_list=[\n",
        "    (\"num_pipeline\", num_pipeline),\n",
        "    (\"cat_pipeline\", cat_pipeline)\n",
        "])\n",
        "\n",
        "# Preparando os dados\n",
        "housing_prepared = full_pipeline.fit_transform(housing)\n",
        "\n",
        "# 1. Experimentando SVR\n",
        "print(\"\\n=== Testando SVR ===\")\n",
        "svr_param_grid = [\n",
        "    {'kernel': ['linear'], 'C': [0.1, 1, 10, 100]},\n",
        "    {'kernel': ['rbf'], 'C': [0.1, 1, 10, 100], 'gamma': [0.01, 0.1, 1, 'scale', 'auto']},\n",
        "]\n",
        "\n",
        "svr = SVR()\n",
        "svr_grid_search = GridSearchCV(svr, svr_param_grid, cv=5, scoring='neg_mean_squared_error', verbose=2, n_jobs=-1)\n",
        "svr_grid_search.fit(housing_prepared, housing_labels)\n",
        "\n",
        "svr_best_params = svr_grid_search.best_params_\n",
        "svr_best_score = np.sqrt(-svr_grid_search.best_score_)\n",
        "print(f\"Melhores parâmetros SVR: {svr_best_params}\")\n",
        "print(f\"Melhor RMSE SVR: {svr_best_score:.2f}\")\n",
        "\n",
        "# 2. RandomizedSearchCV para Random Forest\n",
        "print(\"\\n=== Testando RandomizedSearchCV ===\")\n",
        "param_distribs = {\n",
        "    'n_estimators': randint(low=10, high=200),\n",
        "    'max_features': randint(low=2, high=8),\n",
        "    'bootstrap': [True, False],\n",
        "    'max_depth': [None, 10, 20, 30, 40, 50],\n",
        "    'min_samples_split': randint(low=2, high=20),\n",
        "    'min_samples_leaf': randint(low=1, high=10)\n",
        "}\n",
        "\n",
        "forest_reg = RandomForestRegressor(random_state=42)\n",
        "rnd_search = RandomizedSearchCV(forest_reg, param_distributions=param_distribs,\n",
        "                              n_iter=50, cv=5, scoring='neg_mean_squared_error',\n",
        "                              random_state=42, verbose=2, n_jobs=-1)\n",
        "rnd_search.fit(housing_prepared, housing_labels)\n",
        "\n",
        "rnd_best_params = rnd_search.best_params_\n",
        "rnd_best_score = np.sqrt(-rnd_search.best_score_)\n",
        "print(f\"Melhores parâmetros (Randomized): {rnd_best_params}\")\n",
        "print(f\"Melhor RMSE (Randomized): {rnd_best_score:.2f}\")\n",
        "\n",
        "# 3. Adicionando seleção de features importantes\n",
        "print(\"\\n=== Adicionando seleção de features ===\")\n",
        "best_forest = rnd_search.best_estimator_\n",
        "feature_importances = best_forest.feature_importances_\n",
        "\n",
        "num_pipeline_with_selector = Pipeline([\n",
        "    ('selector', DataFrameSelector(num_attribs)),\n",
        "    ('imputer', SimpleImputer(strategy=\"median\")),\n",
        "    ('attribs_adder', CombinedAttributesAdder()),\n",
        "    ('std_scaler', StandardScaler()),\n",
        "    ('feature_selector', FeatureSelector(feature_importances[:len(num_attribs)+3], threshold=0.01))\n",
        "])\n",
        "\n",
        "full_pipeline_with_selector = FeatureUnion(transformer_list=[\n",
        "    (\"num_pipeline\", num_pipeline_with_selector),\n",
        "    (\"cat_pipeline\", cat_pipeline)\n",
        "])\n",
        "\n",
        "housing_prepared_important = full_pipeline_with_selector.fit_transform(housing)\n",
        "\n",
        "forest_reg.fit(housing_prepared_important, housing_labels)\n",
        "housing_predictions = forest_reg.predict(housing_prepared_important)\n",
        "forest_mse = mean_squared_error(housing_labels, housing_predictions)\n",
        "forest_rmse = np.sqrt(forest_mse)\n",
        "print(f\"RMSE com features selecionadas: {forest_rmse:.2f}\")\n",
        "\n",
        "# 4. Pipeline único completo\n",
        "print(\"\\n=== Criando pipeline único completo ===\")\n",
        "full_pipeline_with_model = Pipeline([\n",
        "    ('preparation', ColumnTransformer([\n",
        "        (\"num\", make_pipeline(\n",
        "            SimpleImputer(strategy=\"median\"),\n",
        "            CombinedAttributesAdder(),\n",
        "            StandardScaler(),\n",
        "            FeatureSelector(feature_importances[:len(num_attribs)+3], threshold=0.01)\n",
        "        ), num_attribs),\n",
        "        (\"cat\", OneHotEncoder(), cat_attribs),\n",
        "    ])),\n",
        "    ('model', RandomForestRegressor(**rnd_best_params))\n",
        "])\n",
        "\n",
        "full_pipeline_with_model.fit(housing, housing_labels)\n",
        "cv_scores = cross_val_score(full_pipeline_with_model, housing, housing_labels,\n",
        "                          scoring=\"neg_mean_squared_error\", cv=5)\n",
        "rmse_scores = np.sqrt(-cv_scores)\n",
        "print(\"Scores de validação cruzada:\")\n",
        "print(\"Scores:\", rmse_scores)\n",
        "print(\"Média:\", rmse_scores.mean())\n",
        "print(\"Desvio padrão:\", rmse_scores.std())\n",
        "\n",
        "# 5. Explorando opções de preparação com GridSearchCV\n",
        "print(\"\\n=== Explorando opções de preparação ===\")\n",
        "param_grid = [\n",
        "    {\n",
        "        'preparation__num__imputer__strategy': ['mean', 'median', 'most_frequent'],\n",
        "        'preparation__num__attribs_adder__add_bedrooms_per_room': [True, False],\n",
        "        'model__n_estimators': [50, 100, 200],\n",
        "        'model__max_features': [4, 6, 8]\n",
        "    }\n",
        "]\n",
        "\n",
        "grid_search_prep = GridSearchCV(full_pipeline_with_model, param_grid, cv=5,\n",
        "                              scoring='neg_mean_squared_error', verbose=2, n_jobs=-1)\n",
        "grid_search_prep.fit(housing, housing_labels)\n",
        "\n",
        "best_prep_params = grid_search_prep.best_params_\n",
        "best_prep_score = np.sqrt(-grid_search_prep.best_score_)\n",
        "print(f\"Melhores parâmetros incluindo preparação: {best_prep_params}\")\n",
        "print(f\"Melhor RMSE incluindo preparação: {best_prep_score:.2f}\")\n",
        "\n",
        "# Avaliação final no conjunto de teste\n",
        "final_model = grid_search_prep.best_estimator_\n",
        "\n",
        "X_test = strat_test_set.drop(\"median_house_value\", axis=1)\n",
        "y_test = strat_test_set[\"median_house_value\"].copy()\n",
        "\n",
        "final_predictions = final_model.predict(X_test)\n",
        "final_mse = mean_squared_error(y_test, final_predictions)\n",
        "final_rmse = np.sqrt(final_mse)\n",
        "print(f\"\\nRMSE final no conjunto de teste: {final_rmse:.2f}\")"
      ]
    }
  ]
}